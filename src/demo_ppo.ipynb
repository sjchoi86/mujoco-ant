{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run PPO on Ant from [here](https://github.com/pat-coady/trpo)\n",
    "#### More descriptions can be found on Patrick Coady's blog regarding [gym and ppo](https://learningai.io/projects/2017/07/28/ai-gym-workout.html) or [descriptions about Ant env](https://gist.github.com/pat-coady/bac60888f011199aad72d2f1e6f5a4fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages Loaded\n"
     ]
    }
   ],
   "source": [
    "import gym,mujoco_py,warnings,time,os,glob,shutil,csv,skvideo.io\n",
    "gym.logger.set_level(40)\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from gym.envs import mujoco\n",
    "from datetime import datetime\n",
    "from util import PID_class,Scaler,Logger,display_frames_as_gif\n",
    "from custom_ant import AntEnvCustom\n",
    "from ppo import NNValueFunction,Policy,run_episode,run_policy,add_value,discount,\\\n",
    "    add_disc_sum_rew,add_gae,build_train_set,log_batch_stats,run_episode_vid\n",
    "np.set_printoptions(precision=2,linewidth=150)\n",
    "%matplotlib inline  \n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "print (\"Packages Loaded\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Ant Environment made by SJ.\n",
      "obs_dim:[111] act_dim:[8]\n",
      "Value Params -- h1: 1120, h2: 74, h3: 5, lr: 0.00116\n",
      "Policy Params -- h1: 1120, h2: 299, h3: 80, lr: 5.2e-05, logvar_speed: 16\n",
      "setting up loss with KL penalty\n"
     ]
    }
   ],
   "source": [
    "env = AntEnvCustom()\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.shape[0]\n",
    "env.reset() # Reset \n",
    "# render_img = env.render(mode='rgb_array')\n",
    "print (\"obs_dim:[%d] act_dim:[%d]\"%(obs_dim,act_dim))\n",
    "\n",
    "obs_dim += 1  # add 1 to obs dimension for time step feature (see run_episode())\n",
    "# Logger\n",
    "env_name = 'Ant'\n",
    "now = datetime.utcnow().strftime(\"%b-%d_%H:%M:%S\")  # create unique directories\n",
    "logger = Logger(logName=env_name,now=now,_NOTUSE=True)\n",
    "aigym_path = os.path.join('/tmp', env_name, now)\n",
    "# Scaler\n",
    "scaler = Scaler(obs_dim)\n",
    "# Value function\n",
    "hid1_mult = 10\n",
    "val_func = NNValueFunction(obs_dim, hid1_mult)\n",
    "# Policy Function\n",
    "kl_targ = 0.003\n",
    "policy_logvar = -1.0\n",
    "policy = Policy(obs_dim, act_dim, kl_targ, hid1_mult, policy_logvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run policy for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observes shape: (23, 112)\n",
      "actions shape: (23, 8)\n",
      "rewards shape: (23,)\n",
      "unscaled_obs shape: (23, 112)\n",
      "values shape: (23,)\n",
      "disc_sum_rew shape: (23,)\n",
      "advantages shape: (23,)\n"
     ]
    }
   ],
   "source": [
    "trajectories = run_policy(env, policy, scaler, logger, episodes=5)\n",
    "add_value(trajectories, val_func)  # add estimated values to episodes\n",
    "gamma = 0.995 # Discount factor \n",
    "lam = 0.95 # Lambda for GAE\n",
    "add_disc_sum_rew(trajectories, gamma)  # calculated discounted sum of Rs\n",
    "add_gae(trajectories, gamma, lam)  # calculate advantage\n",
    "print ('observes shape:',trajectories[0]['observes'].shape)\n",
    "print ('actions shape:',trajectories[0]['actions'].shape)\n",
    "print ('rewards shape:',trajectories[0]['rewards'].shape)\n",
    "print ('unscaled_obs shape:',trajectories[0]['unscaled_obs'].shape)\n",
    "print ('values shape:',trajectories[0]['values'].shape)\n",
    "print ('disc_sum_rew shape:',trajectories[0]['disc_sum_rew'].shape)\n",
    "print ('advantages shape:',trajectories[0]['advantages'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_VID = True\n",
    "MAKE_GIF = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/10000](#total:50) sumRwd:[-162.254](cntct:-0.082+ctrl:-139.800+fwd:1.986+head:-96.739+srv:72.380)\n",
      "Creating window glfw\n",
      "  [^] sumRwd:[-228.553] Xdisp:[-0.655] hDisp:[89.1]\n",
      "[vids/ant_ppo_epoch000.mp4] saved.\n",
      "[1/10000](#total:100) sumRwd:[-195.205](cntct:-0.089+ctrl:-162.277+fwd:-0.231+head:-112.988+srv:80.380)\n",
      "[2/10000](#total:150) sumRwd:[-139.927](cntct:-0.065+ctrl:-132.447+fwd:-7.415+head:-62.219+srv:62.220)\n",
      "[3/10000](#total:200) sumRwd:[-169.508](cntct:-0.085+ctrl:-155.476+fwd:1.780+head:-91.087+srv:75.360)\n",
      "[4/10000](#total:250) sumRwd:[-173.839](cntct:-0.086+ctrl:-163.439+fwd:-2.850+head:-87.064+srv:79.600)\n",
      "[5/10000](#total:300) sumRwd:[-153.114](cntct:-0.072+ctrl:-141.523+fwd:-1.319+head:-79.060+srv:68.860)\n",
      "[6/10000](#total:350) sumRwd:[-163.952](cntct:-0.073+ctrl:-141.372+fwd:-2.699+head:-88.188+srv:68.380)\n",
      "[7/10000](#total:400) sumRwd:[-162.866](cntct:-0.081+ctrl:-153.525+fwd:-3.535+head:-80.125+srv:74.400)\n",
      "[8/10000](#total:450) sumRwd:[-223.904](cntct:-0.083+ctrl:-163.315+fwd:-8.100+head:-131.506+srv:79.100)\n",
      "[9/10000](#total:500) sumRwd:[-188.422](cntct:-0.089+ctrl:-162.754+fwd:-4.296+head:-100.223+srv:78.940)\n",
      "[10/10000](#total:550) sumRwd:[-126.381](cntct:-0.070+ctrl:-136.768+fwd:-0.447+head:-55.096+srv:66.000)\n",
      "[11/10000](#total:600) sumRwd:[-190.297](cntct:-0.085+ctrl:-172.096+fwd:-1.356+head:-99.320+srv:82.560)\n",
      "[12/10000](#total:650) sumRwd:[-141.208](cntct:-0.066+ctrl:-135.690+fwd:-5.878+head:-64.294+srv:64.720)\n",
      "[13/10000](#total:700) sumRwd:[-179.097](cntct:-0.074+ctrl:-145.511+fwd:0.156+head:-103.768+srv:70.100)\n",
      "[14/10000](#total:750) sumRwd:[-206.177](cntct:-0.093+ctrl:-178.975+fwd:-1.337+head:-111.632+srv:85.860)\n",
      "[15/10000](#total:800) sumRwd:[-192.076](cntct:-0.077+ctrl:-159.071+fwd:-6.647+head:-102.760+srv:76.480)\n",
      "[16/10000](#total:850) sumRwd:[-150.114](cntct:-0.075+ctrl:-151.942+fwd:-10.604+head:-59.354+srv:71.860)\n",
      "[17/10000](#total:900) sumRwd:[-178.761](cntct:-0.069+ctrl:-135.624+fwd:-8.892+head:-98.617+srv:64.440)\n",
      "[18/10000](#total:950) sumRwd:[-160.717](cntct:-0.073+ctrl:-139.503+fwd:-3.133+head:-84.249+srv:66.240)\n",
      "[19/10000](#total:1000) sumRwd:[-148.853](cntct:-0.071+ctrl:-149.136+fwd:1.115+head:-70.861+srv:70.100)\n",
      "[20/10000](#total:1050) sumRwd:[-173.328](cntct:-0.077+ctrl:-149.138+fwd:-4.403+head:-90.311+srv:70.600)\n",
      "  [^] sumRwd:[-18.555] Xdisp:[-0.243] hDisp:[5.2]\n",
      "[vids/ant_ppo_epoch020.mp4] saved.\n",
      "[21/10000](#total:1100) sumRwd:[-144.128](cntct:-0.070+ctrl:-135.130+fwd:0.923+head:-73.811+srv:63.960)\n",
      "[22/10000](#total:1150) sumRwd:[-122.504](cntct:-0.058+ctrl:-121.100+fwd:-2.414+head:-55.672+srv:56.740)\n",
      "[23/10000](#total:1200) sumRwd:[-132.562](cntct:-0.062+ctrl:-127.570+fwd:1.104+head:-65.714+srv:59.680)\n",
      "[24/10000](#total:1250) sumRwd:[-151.207](cntct:-0.073+ctrl:-142.579+fwd:-2.534+head:-73.100+srv:67.080)\n",
      "[25/10000](#total:1300) sumRwd:[-170.295](cntct:-0.062+ctrl:-131.932+fwd:-6.903+head:-92.458+srv:61.060)\n",
      "[26/10000](#total:1350) sumRwd:[-200.124](cntct:-0.095+ctrl:-181.075+fwd:-1.555+head:-102.619+srv:85.220)\n",
      "[27/10000](#total:1400) sumRwd:[-109.182](cntct:-0.055+ctrl:-117.178+fwd:1.800+head:-48.650+srv:54.900)\n",
      "[28/10000](#total:1450) sumRwd:[-154.040](cntct:-0.067+ctrl:-141.139+fwd:-3.680+head:-75.234+srv:66.080)\n",
      "[29/10000](#total:1500) sumRwd:[-142.443](cntct:-0.064+ctrl:-129.944+fwd:-9.573+head:-63.521+srv:60.660)\n",
      "[30/10000](#total:1550) sumRwd:[-99.271](cntct:-0.050+ctrl:-104.399+fwd:-3.732+head:-40.310+srv:49.220)\n",
      "[31/10000](#total:1600) sumRwd:[-153.791](cntct:-0.068+ctrl:-141.804+fwd:-4.083+head:-74.035+srv:66.200)\n",
      "[32/10000](#total:1650) sumRwd:[-133.304](cntct:-0.063+ctrl:-130.738+fwd:-5.312+head:-59.491+srv:62.300)\n",
      "[33/10000](#total:1700) sumRwd:[-133.816](cntct:-0.060+ctrl:-127.691+fwd:-7.405+head:-58.380+srv:59.720)\n",
      "[34/10000](#total:1750) sumRwd:[-151.395](cntct:-0.075+ctrl:-146.396+fwd:-3.918+head:-69.466+srv:68.460)\n",
      "[35/10000](#total:1800) sumRwd:[-201.988](cntct:-0.084+ctrl:-164.695+fwd:-2.334+head:-110.955+srv:76.080)\n",
      "[36/10000](#total:1850) sumRwd:[-166.882](cntct:-0.077+ctrl:-155.802+fwd:0.701+head:-84.784+srv:73.080)\n",
      "[37/10000](#total:1900) sumRwd:[-168.371](cntct:-0.079+ctrl:-160.908+fwd:2.922+head:-84.445+srv:74.140)\n",
      "[38/10000](#total:1950) sumRwd:[-138.691](cntct:-0.067+ctrl:-125.429+fwd:-3.881+head:-67.094+srv:57.780)\n",
      "[39/10000](#total:2000) sumRwd:[-139.422](cntct:-0.066+ctrl:-137.178+fwd:1.545+head:-66.742+srv:63.020)\n",
      "[40/10000](#total:2050) sumRwd:[-148.860](cntct:-0.061+ctrl:-130.901+fwd:-4.955+head:-72.882+srv:59.940)\n",
      "  [^] sumRwd:[-4.369] Xdisp:[0.124] hDisp:[3.7]\n",
      "[vids/ant_ppo_epoch040.mp4] saved.\n",
      "[41/10000](#total:2100) sumRwd:[-106.903](cntct:-0.046+ctrl:-100.865+fwd:-3.478+head:-49.714+srv:47.200)\n",
      "[42/10000](#total:2150) sumRwd:[-123.065](cntct:-0.062+ctrl:-128.339+fwd:-1.491+head:-52.273+srv:59.100)\n",
      "[43/10000](#total:2200) sumRwd:[-107.109](cntct:-0.050+ctrl:-104.460+fwd:-0.595+head:-50.184+srv:48.180)\n",
      "[44/10000](#total:2250) sumRwd:[-91.549](cntct:-0.052+ctrl:-107.605+fwd:-2.290+head:-30.822+srv:49.220)\n",
      "[45/10000](#total:2300) sumRwd:[-87.028](cntct:-0.044+ctrl:-93.967+fwd:-3.722+head:-33.414+srv:44.120)\n",
      "[46/10000](#total:2350) sumRwd:[-135.933](cntct:-0.058+ctrl:-128.235+fwd:-0.024+head:-67.356+srv:59.740)\n",
      "[47/10000](#total:2400) sumRwd:[-102.242](cntct:-0.051+ctrl:-101.320+fwd:4.471+head:-51.861+srv:46.520)\n",
      "[48/10000](#total:2450) sumRwd:[-122.786](cntct:-0.052+ctrl:-111.579+fwd:-2.603+head:-60.492+srv:51.940)\n",
      "[49/10000](#total:2500) sumRwd:[-132.292](cntct:-0.056+ctrl:-121.369+fwd:-4.760+head:-61.328+srv:55.220)\n",
      "[50/10000](#total:2550) sumRwd:[-110.050](cntct:-0.057+ctrl:-118.989+fwd:-3.288+head:-42.196+srv:54.480)\n",
      "[51/10000](#total:2600) sumRwd:[-186.680](cntct:-0.074+ctrl:-152.222+fwd:1.862+head:-106.285+srv:70.040)\n",
      "[52/10000](#total:2650) sumRwd:[-172.064](cntct:-0.072+ctrl:-150.041+fwd:-2.818+head:-89.312+srv:70.180)\n",
      "[53/10000](#total:2700) sumRwd:[-147.754](cntct:-0.060+ctrl:-126.105+fwd:-1.864+head:-77.265+srv:57.540)\n",
      "[54/10000](#total:2750) sumRwd:[-111.266](cntct:-0.055+ctrl:-117.824+fwd:-1.387+head:-47.019+srv:55.020)\n",
      "[55/10000](#total:2800) sumRwd:[-83.572](cntct:-0.046+ctrl:-96.917+fwd:-2.720+head:-29.129+srv:45.240)\n",
      "[56/10000](#total:2850) sumRwd:[-140.516](cntct:-0.061+ctrl:-131.896+fwd:-0.283+head:-67.336+srv:59.060)\n",
      "[57/10000](#total:2900) sumRwd:[-117.356](cntct:-0.051+ctrl:-111.013+fwd:2.253+head:-60.844+srv:52.300)\n",
      "[58/10000](#total:2950) sumRwd:[-126.667](cntct:-0.050+ctrl:-104.160+fwd:1.315+head:-71.451+srv:47.680)\n",
      "[59/10000](#total:3000) sumRwd:[-88.969](cntct:-0.045+ctrl:-100.265+fwd:-1.940+head:-32.679+srv:45.960)\n",
      "[60/10000](#total:3050) sumRwd:[-124.521](cntct:-0.059+ctrl:-120.591+fwd:-1.365+head:-57.446+srv:54.940)\n",
      "  [^] sumRwd:[-138.767] Xdisp:[0.822] hDisp:[-174.3]\n",
      "[vids/ant_ppo_epoch060.mp4] saved.\n",
      "[61/10000](#total:3100) sumRwd:[-139.356](cntct:-0.069+ctrl:-137.758+fwd:-1.967+head:-62.122+srv:62.560)\n",
      "[62/10000](#total:3150) sumRwd:[-114.519](cntct:-0.052+ctrl:-115.981+fwd:-0.431+head:-50.535+srv:52.480)\n",
      "[63/10000](#total:3200) sumRwd:[-100.023](cntct:-0.046+ctrl:-104.393+fwd:0.323+head:-44.587+srv:48.680)\n",
      "[64/10000](#total:3250) sumRwd:[-125.832](cntct:-0.057+ctrl:-124.489+fwd:-4.669+head:-52.418+srv:55.800)\n",
      "[65/10000](#total:3300) sumRwd:[-135.842](cntct:-0.059+ctrl:-121.319+fwd:-4.115+head:-65.148+srv:54.800)\n",
      "[66/10000](#total:3350) sumRwd:[-142.326](cntct:-0.053+ctrl:-115.464+fwd:-4.732+head:-74.557+srv:52.480)\n",
      "[67/10000](#total:3400) sumRwd:[-142.159](cntct:-0.063+ctrl:-131.376+fwd:-6.358+head:-63.642+srv:59.280)\n",
      "[68/10000](#total:3450) sumRwd:[-137.275](cntct:-0.054+ctrl:-118.040+fwd:-2.340+head:-69.782+srv:52.940)\n",
      "[69/10000](#total:3500) sumRwd:[-124.436](cntct:-0.060+ctrl:-129.466+fwd:-1.952+head:-51.859+srv:58.900)\n",
      "[70/10000](#total:3550) sumRwd:[-113.889](cntct:-0.055+ctrl:-123.521+fwd:0.465+head:-46.139+srv:55.360)\n",
      "[71/10000](#total:3600) sumRwd:[-112.222](cntct:-0.044+ctrl:-103.251+fwd:-4.219+head:-51.168+srv:46.460)\n",
      "[72/10000](#total:3650) sumRwd:[-130.676](cntct:-0.057+ctrl:-128.623+fwd:0.015+head:-60.032+srv:58.020)\n",
      "[73/10000](#total:3700) sumRwd:[-112.450](cntct:-0.056+ctrl:-113.501+fwd:-4.083+head:-46.309+srv:51.500)\n",
      "[74/10000](#total:3750) sumRwd:[-104.639](cntct:-0.051+ctrl:-104.169+fwd:-0.220+head:-45.799+srv:45.600)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75/10000](#total:3800) sumRwd:[-122.396](cntct:-0.052+ctrl:-115.623+fwd:-4.978+head:-53.802+srv:52.060)\n",
      "[76/10000](#total:3850) sumRwd:[-153.374](cntct:-0.060+ctrl:-134.919+fwd:-5.295+head:-74.060+srv:60.960)\n",
      "[77/10000](#total:3900) sumRwd:[-116.258](cntct:-0.061+ctrl:-130.017+fwd:-4.960+head:-40.779+srv:59.560)\n",
      "[78/10000](#total:3950) sumRwd:[-148.073](cntct:-0.061+ctrl:-130.034+fwd:3.679+head:-79.397+srv:57.740)\n",
      "[79/10000](#total:4000) sumRwd:[-136.601](cntct:-0.056+ctrl:-121.111+fwd:-3.930+head:-66.884+srv:55.380)\n",
      "[80/10000](#total:4050) sumRwd:[-116.480](cntct:-0.051+ctrl:-110.322+fwd:0.122+head:-55.050+srv:48.820)\n",
      "  [^] sumRwd:[-920.448] Xdisp:[-0.757] hDisp:[176.5]\n",
      "[vids/ant_ppo_epoch080.mp4] saved.\n",
      "[81/10000](#total:4100) sumRwd:[-122.395](cntct:-0.054+ctrl:-116.605+fwd:-3.468+head:-53.128+srv:50.860)\n",
      "[82/10000](#total:4150) sumRwd:[-125.019](cntct:-0.057+ctrl:-128.950+fwd:-5.175+head:-48.917+srv:58.080)\n",
      "[83/10000](#total:4200) sumRwd:[-113.111](cntct:-0.045+ctrl:-107.456+fwd:-2.930+head:-50.860+srv:48.180)\n",
      "[84/10000](#total:4250) sumRwd:[-100.325](cntct:-0.042+ctrl:-99.514+fwd:-0.198+head:-44.451+srv:43.880)\n",
      "[85/10000](#total:4300) sumRwd:[-120.046](cntct:-0.050+ctrl:-107.959+fwd:0.826+head:-61.443+srv:48.580)\n",
      "[86/10000](#total:4350) sumRwd:[-102.329](cntct:-0.047+ctrl:-107.352+fwd:-1.485+head:-39.884+srv:46.440)\n",
      "[87/10000](#total:4400) sumRwd:[-98.063](cntct:-0.049+ctrl:-104.519+fwd:-6.125+head:-35.069+srv:47.700)\n",
      "[88/10000](#total:4450) sumRwd:[-86.100](cntct:-0.041+ctrl:-90.134+fwd:1.305+head:-38.171+srv:40.940)\n",
      "[89/10000](#total:4500) sumRwd:[-92.874](cntct:-0.045+ctrl:-98.768+fwd:-1.412+head:-36.169+srv:43.520)\n",
      "[90/10000](#total:4550) sumRwd:[-80.117](cntct:-0.042+ctrl:-89.524+fwd:-2.270+head:-27.721+srv:39.440)\n",
      "[91/10000](#total:4600) sumRwd:[-141.421](cntct:-0.053+ctrl:-121.586+fwd:-4.552+head:-69.170+srv:53.940)\n",
      "[92/10000](#total:4650) sumRwd:[-136.398](cntct:-0.058+ctrl:-132.744+fwd:-1.047+head:-61.509+srv:58.960)\n",
      "[93/10000](#total:4700) sumRwd:[-115.049](cntct:-0.049+ctrl:-115.184+fwd:-1.042+head:-50.334+srv:51.560)\n",
      "[94/10000](#total:4750) sumRwd:[-123.764](cntct:-0.055+ctrl:-118.270+fwd:-5.137+head:-52.203+srv:51.900)\n",
      "[95/10000](#total:4800) sumRwd:[-153.827](cntct:-0.069+ctrl:-145.890+fwd:-1.255+head:-71.993+srv:65.380)\n",
      "[96/10000](#total:4850) sumRwd:[-91.574](cntct:-0.043+ctrl:-93.032+fwd:-2.267+head:-37.692+srv:41.460)\n",
      "[97/10000](#total:4900) sumRwd:[-122.862](cntct:-0.053+ctrl:-120.472+fwd:-2.324+head:-54.053+srv:54.040)\n",
      "[98/10000](#total:4950) sumRwd:[-118.532](cntct:-0.055+ctrl:-118.036+fwd:-2.808+head:-51.013+srv:53.380)\n",
      "[99/10000](#total:5000) sumRwd:[-121.231](cntct:-0.053+ctrl:-114.113+fwd:-3.360+head:-54.365+srv:50.660)\n",
      "[100/10000](#total:5050) sumRwd:[-139.372](cntct:-0.054+ctrl:-124.229+fwd:-2.660+head:-68.468+srv:56.040)\n",
      "  [^] sumRwd:[-221.613] Xdisp:[0.164] hDisp:[-155.4]\n",
      "[vids/ant_ppo_epoch100.mp4] saved.\n",
      "[101/10000](#total:5100) sumRwd:[-84.144](cntct:-0.043+ctrl:-100.299+fwd:3.248+head:-31.690+srv:44.640)\n",
      "[102/10000](#total:5150) sumRwd:[-105.485](cntct:-0.049+ctrl:-110.096+fwd:-1.352+head:-42.808+srv:48.820)\n",
      "[103/10000](#total:5200) sumRwd:[-76.717](cntct:-0.037+ctrl:-84.857+fwd:-0.655+head:-28.589+srv:37.420)\n",
      "[104/10000](#total:5250) sumRwd:[-80.363](cntct:-0.035+ctrl:-85.781+fwd:1.102+head:-33.748+srv:38.100)\n",
      "[105/10000](#total:5300) sumRwd:[-69.276](cntct:-0.036+ctrl:-83.684+fwd:-2.121+head:-21.096+srv:37.660)\n",
      "[106/10000](#total:5350) sumRwd:[-71.080](cntct:-0.036+ctrl:-84.132+fwd:1.909+head:-26.122+srv:37.300)\n",
      "[107/10000](#total:5400) sumRwd:[-133.911](cntct:-0.050+ctrl:-115.649+fwd:-5.093+head:-64.259+srv:51.140)\n",
      "[108/10000](#total:5450) sumRwd:[-87.018](cntct:-0.039+ctrl:-87.382+fwd:-1.027+head:-36.650+srv:38.080)\n",
      "[109/10000](#total:5500) sumRwd:[-106.407](cntct:-0.050+ctrl:-116.001+fwd:2.354+head:-43.550+srv:50.840)\n",
      "[110/10000](#total:5550) sumRwd:[-75.459](cntct:-0.037+ctrl:-85.705+fwd:-0.361+head:-26.417+srv:37.060)\n",
      "[111/10000](#total:5600) sumRwd:[-103.585](cntct:-0.044+ctrl:-102.659+fwd:1.348+head:-47.210+srv:44.980)\n",
      "[112/10000](#total:5650) sumRwd:[-89.601](cntct:-0.040+ctrl:-91.057+fwd:0.008+head:-38.613+srv:40.100)\n",
      "[113/10000](#total:5700) sumRwd:[-112.522](cntct:-0.048+ctrl:-112.905+fwd:0.016+head:-48.545+srv:48.960)\n",
      "[114/10000](#total:5750) sumRwd:[-108.048](cntct:-0.042+ctrl:-96.614+fwd:-6.083+head:-47.568+srv:42.260)\n",
      "[115/10000](#total:5800) sumRwd:[-143.795](cntct:-0.051+ctrl:-119.960+fwd:-2.740+head:-72.783+srv:51.740)\n",
      "[116/10000](#total:5850) sumRwd:[-113.683](cntct:-0.054+ctrl:-118.185+fwd:0.837+head:-48.481+srv:52.200)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-46df7c87e08f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_epoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxEpoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# 1. Run policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrajectories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# 2. Get (predict) value from the critic network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0madd_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrajectories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_func\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# add estimated values to episodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/mujoco-ant/src/ppo.py\u001b[0m in \u001b[0;36mrun_policy\u001b[0;34m(env, policy, scaler, logger, episodes)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;31m# print (\"epi:[%d/%d]\"%(e,episodes))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mobserves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munscaled_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrDetails\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m             \u001b[0mrun_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m         \u001b[0mtotal_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mobserves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         trajectory = {'observes': observes,\n",
      "\u001b[0;32m~/github/mujoco-ant/src/ppo.py\u001b[0m in \u001b[0;36mrun_episode\u001b[0;34m(env, policy, scaler, animate)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0mobserves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;31m# Sample action and make it rank two\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;31m# Forward step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/mujoco-ant/src/ppo.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampled_act\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madvantages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "maxEpoch  = 10000\n",
    "batchSize = 50\n",
    "for _epoch in range(maxEpoch):\n",
    "    # 1. Run policy\n",
    "    trajectories = run_policy(env, policy, scaler, logger, episodes=batchSize)\n",
    "    # 2. Get (predict) value from the critic network \n",
    "    add_value(trajectories, val_func)  # add estimated values to episodes\n",
    "    # 3. Get GAE\n",
    "    gamma = 0.995 # Discount factor \n",
    "    lam = 0.95 # Lambda for GAE\n",
    "    add_disc_sum_rew(trajectories, gamma)  # calculated discounted sum of Rs\n",
    "    add_gae(trajectories, gamma, lam)  # calculate advantage\n",
    "    # concatenate all episodes into single NumPy arrays\n",
    "    observes, actions, advantages, disc_sum_rew = build_train_set(trajectories)\n",
    "    # add various stats to training log:\n",
    "    # log_batch_stats(observes, actions, advantages, disc_sum_rew, logger, episode)\n",
    "    # Update\n",
    "    policy.update(observes, actions, advantages, logger)  # update policy\n",
    "    val_func.fit(observes, disc_sum_rew, logger)  # update value function\n",
    "    # logger.write(display=True)  # write logger results to file and stdout\n",
    "    \n",
    "    # Print\n",
    "    for _tIdx in range(len(trajectories)):\n",
    "        rs = trajectories[_tIdx]['rewards']\n",
    "        if _tIdx == 0: rTotal = rs\n",
    "        else: rTotal = np.concatenate((rTotal,rs))\n",
    "        # Reward details      \n",
    "    reward_contacts,reward_ctrls,reward_forwards,reward_headings,reward_survives = [],[],[],[],[]\n",
    "    tickSum = 0\n",
    "    for traj in trajectories:\n",
    "        tickSum += traj['rewards'].shape[0]\n",
    "        cTraj = traj['rDetails']\n",
    "        for _iIdx in range(len(cTraj)):\n",
    "            reward_contacts.append(cTraj[_iIdx]['reward_contact'])\n",
    "            reward_ctrls.append(cTraj[_iIdx]['reward_ctrl'])\n",
    "            reward_forwards.append(cTraj[_iIdx]['reward_forward'])\n",
    "            reward_headings.append(cTraj[_iIdx]['reward_heading'])\n",
    "            reward_survives.append(cTraj[_iIdx]['reward_survive'])\n",
    "    tickAvg = tickSum / batchsize\n",
    "    sumRwd = rTotal.sum() / batchSize\n",
    "    sumReward_contact = np.asarray(reward_contacts).sum() / batchSize\n",
    "    sumReward_ctrl = np.asarray(reward_ctrls).sum() / batchSize\n",
    "    sumReward_forward = np.asarray(reward_forwards).sum() / batchSize\n",
    "    sumReward_heading = np.asarray(reward_headings).sum() / batchSize\n",
    "    sumReward_survive = np.asarray(reward_survives).sum() / batchSize\n",
    "    print (\"[%d/%d](#total:%d) sumRwd:[%.3f](cntct:%.3f+ctrl:%.3f+fwd:%.3f+head:%.3f+srv:%.3f) tickAvg:[%d]\"%\n",
    "           (_epoch,maxEpoch,(_epoch+1)*batchSize,sumRwd,\n",
    "           sumReward_contact,sumReward_ctrl,sumReward_forward,sumReward_heading,sumReward_survive,tickAvg))\n",
    "    \n",
    "    # SHOW EVERY \n",
    "    PLOT_EVERY = 20 \n",
    "    DO_ANIMATE = False\n",
    "    if ((_epoch%PLOT_EVERY)==0 ) | (_epoch==(maxEpoch-1)):\n",
    "        ret = run_episode_vid(env, policy, scaler)\n",
    "        print (\"  [^] sumRwd:[%.3f] Xdisp:[%.3f] hDisp:[%.1f]\"%\n",
    "               (np.asarray(ret['rewards']).sum(),ret['xDisp'],ret['hDisp']))\n",
    "        if MAKE_GIF:\n",
    "            display_frames_as_gif(ret['frames'])\n",
    "        if SAVE_VID:\n",
    "            outputdata = np.asarray(ret['frames']).astype(np.uint8)\n",
    "            vidName = 'vids/ant_ppo_epoch%03d.mp4'%(_epoch)\n",
    "            skvideo.io.vwrite(vidName,outputdata)\n",
    "            print (\"[%s] saved.\"%(vidName))\n",
    "print (\"Done.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animate final motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_VID_FINAL = True\n",
    "MAKE_GIF_FINAL = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _i in range(3):\n",
    "    ret = run_episode_vid(env, policy, scaler)\n",
    "    if MAKE_GIF_FINAL:\n",
    "        display_frames_as_gif(ret['frames'])\n",
    "    if SAVE_VID_FINAL:\n",
    "        outputdata = np.asarray(ret['frames']).astype(np.uint8)\n",
    "        vidName = 'vids/ant_ppo_final_%d.mp4'%(_i)\n",
    "        skvideo.io.vwrite(vidName,outputdata)\n",
    "        print (\"[%s] saved.\"%(vidName))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_CLOSE = False # There is no turning back. \n",
    "if DO_CLOSE:\n",
    "    logger.close()\n",
    "    policy.close_sess()\n",
    "    val_func.close_sess()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
